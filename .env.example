# ─── LLM Provider ────────────────────────────────────────────────
# Base URL for the LLM API (leave empty for default OpenAI endpoint)
BASE_URL=
# API key for your LLM provider (OpenAI or Google Gemini)
API_KEY=your-api-key-here

# ─── External API Keys (optional, for tool functions) ───────────
# Serper.dev API key — enables web search tool
SERPER_DEV_API_KEY=
# Jina API key — enables web content extraction tool
JINA_API_KEY=

# ─── Application Settings ───────────────────────────────────────
# Logging: DEBUG | INFO | WARNING | ERROR | CRITICAL
LOG_LEVEL=INFO
# Environment: development | production
ENVIRONMENT=development

# ─── Paths (defaults work for Docker; override for local dev) ───
# VUEGRAPHS_DB_PATH=data/vuegraphs.db
# SERVER_LOG_FILE=logs/server.log
# TEMP_CODE_DIR=temp

# ─── Misc ───────────────────────────────────────────────────────
# Timeout in seconds for installing Python libraries in code-exec nodes
# LIB_INSTALL_TIMEOUT=120
# macOS: auto-clean attachment temp files (0 = off, 1 = on)
# MAC_AUTO_CLEAN_ATTACHMENTS=0
